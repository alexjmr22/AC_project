{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b033fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho treino:      69\n",
      "Tamanho validação:   23\n",
      "Tamanho teste:       24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = \"dataR2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "X = df.drop(columns=[\"Classification\"])  \n",
    "y = df[\"Classification\"]\n",
    "\n",
    "# (80%) de treino e validaçao / (20%) de teste\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 60% de treino / 20% de validação \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "print(f\"Tamanho treino:      {len(X_train)}\")\n",
    "print(f\"Tamanho validação:   {len(X_val)}\")\n",
    "print(f\"Tamanho teste:       {len(X_test)}\")\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\", index=False)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb493ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked features (by H)\n",
      "BMI --> 0.653 (p=0.419)\n",
      "Age --> 0.127 (p=0.722)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Glucose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 56>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpvals[name]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 5) Seleção “significativas” (nível 5%)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m kruskal_selected_features \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fnames \u001b[38;5;28;01mif\u001b[39;00m pvals[f] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mkruskal_selected_features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, kruskal_selected_features)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 6) (Opcional) reduzir datasets já com estas features\u001b[39;00m\n",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpvals[name]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 5) Seleção “significativas” (nível 5%)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m kruskal_selected_features \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fnames \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpvals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mkruskal_selected_features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, kruskal_selected_features)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 6) (Opcional) reduzir datasets já com estas features\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Glucose'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "#--------------------------feature selection --------------------------\n",
    "#Kruskal-Wallis\n",
    "kruskal_selected_features = []\n",
    "p_values = {}\n",
    "classes = np.unique(y_train)\n",
    "for feature in X_train.columns:\n",
    "    groups = []\n",
    "    for have_c in classes:\n",
    "        groups.append(X_train.loc[y_train == have_c, feature]) #faz uma lista dependendo do valor do classification\n",
    "\n",
    "    stat, p = kruskal(*groups) #stat fica com o valor H e p fica com o p-value\n",
    "    p_values[feature] = p\n",
    "    \n",
    "    # Selecionar features com diferença estatisticamente significativa  (5% significance level)\n",
    "    if p < 0.05:\n",
    "        kruskal_selected_features.append(feature)\n",
    "\n",
    "print(\"kruskal_selected_features:\", kruskal_selected_features)\n",
    "\n",
    "\n",
    "\n",
    "# Reduzir datasets apenas às features selecionadas pelo Kruskal-Wallis\n",
    "X_krus_train_sel = X_train[kruskal_selected_features]\n",
    "X_krus_val_sel = X_val[kruskal_selected_features]\n",
    "X_krus_test_sel = X_test[kruskal_selected_features]\n",
    "\n",
    "\n",
    "#ROC-AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "roc_auc_scores = {}\n",
    "roc_auc_selected_features_auc = []\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    x_feat = X_train[feature].values\n",
    "\n",
    "    # Calcular ROC-AUC\n",
    "    auc = roc_auc_score(y_train, x_feat)    \n",
    "    roc_auc_scores[feature] = auc\n",
    "    \n",
    "    # Critério de seleção (tipicamente AUC > 0.6 é considerado relevante nas aulas)\n",
    "    if auc > 0.6:\n",
    "        roc_auc_selected_features_auc.append(feature)\n",
    "\n",
    "print(\"\\nroc_auc_selected_features:\", roc_auc_selected_features_auc)\n",
    "\n",
    "# Reduzir datasets apenas às features selecionadas pelo ROC-AUC\n",
    "X_auc_train_sel = X_train[roc_auc_selected_features_auc]\n",
    "X_auc_val_sel   = X_val[roc_auc_selected_features_auc]\n",
    "X_auc_test_sel  = X_test[roc_auc_selected_features_auc]\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
